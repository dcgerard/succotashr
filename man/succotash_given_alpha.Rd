% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/succotash.R
\name{succotash_given_alpha}
\alias{succotash_given_alpha}
\title{Maximize the SUCCOTASH log-likelihood and return posterior
summaries.}
\usage{
succotash_given_alpha(Y, alpha, sig_diag, num_em_runs = 10,
  print_steps = FALSE, tau_seq = NULL, em_pi_init = NULL, lambda = NULL,
  em_Z_init = NULL, em_itermax = 1500, em_tol = 10^-6,
  em_z_start_sd = 1, em_pi_init_type = "random",
  lambda_type = "zero_conc", lambda0 = 10)
}
\arguments{
\item{Y}{A matrix of dimension \code{p} by \code{1}. These are the
observed regression coefficients of the observed variables.}

\item{alpha}{A matrix. This is of dimension \code{p} by \code{k}
and are the coefficients to the confounding variables.}

\item{sig_diag}{A vector of length \code{p} containing the
variances of the observations.}

\item{num_em_runs}{How many times should we run the EM algorithm?}

\item{print_steps}{A logical. Should we write the updates after
each EM algorithm?}

\item{tau_seq}{A vector of length \code{M} containing the standard
deviations (not variances) of the mixing distributions.}

\item{em_pi_init}{A vector of length \code{M} containing the
starting values of \eqn{\pi}. If \code{NULL}, then one of three
options are implemented in calculating \code{pi_init} based on
the value of \code{pi_init_type}.}

\item{lambda}{A vector. This is a length \code{M} vector with the
regularization parameters for the mixing proportions. If
\code{NULL} then refer to \code{lambda_type}.}

\item{em_Z_init}{A \code{k} by \code{1} matrix. These are the
initial values of the unobserved covariates. If its value is
\code{NULL}, then each element of \code{Z_init} will be drawn
from a mean zero normal with standard deviation
\code{z_start_sd}.}

\item{em_itermax}{An integer. The maximum number of fixed-point
iterations to run the EM algorithm.}

\item{em_tol}{A numeric. The stopping criterion is the absolute
difference of the ratio of subsequent iterations'
log-likelihoods from 1.}

\item{em_z_start_sd}{A positive numeric. If \code{Z_init} is
\code{NULL}, then the starting values for \eqn{Z} are drawn
from a mean zero normal with standard devation
\code{z_start_sd}.}

\item{em_pi_init_type}{How should we choose the initial values of
\eqn{\pi}.  Possible values of \code{"random"},
\code{"uniform"}, and \code{"zero_conc"}. If \code{"random"}
then the initial values of \eqn{\pi} are drawn uniformly over
the probability simplex. If \code{"uniform"}, then each element
of \code{pi_init} is given mass \code{1 / M}. If
\code{"zero_conc"} then the last \code{M - 1} elements of
\code{pi_init} are given mass \code{1 / p} and
\code{pi_init[1]} is given mass \code{1 - sum(pi_init[2:M])}.}

\item{lambda_type}{If \code{lambda} is \code{NULL}, then how should
we choose the regularization parameters. Two options are
available. If \code{lambda_type} is \code{"zero_conc"}, then
\code{lambda[1] = 10} and \code{lambda[2:M] = 1}. If
\code{lambda_type} is \code{"ones"} then \code{lambda = 1}.}

\item{lambda0}{If \code{lambda_type = "zero_conc"}, then
\code{lambda0} is the amount to penalize \code{pi0}.}
}
\value{
\code{Z} A matrix  of dimension \code{k} by  \code{1}. The
    estimates of the confounder covariates.

  \code{pi_vals} A vector of length \code{M}. The estimates of the
  mixing proportions.

  \code{tau_seq} A vector of length \code{M}. The variances of the
  mixing distribution.

  \code{lfdr} (local false discovery rate) A vector of length
  \code{p}. The posterior probability that \eqn{\beta_j = 0}.

  \code{lfsr} (local false sign rate) A vector of length
  \code{p}. The posterior probability of making a sign error.

  \code{qvals} A vector of length \code{p}. The q-values.

  \code{betahat} A vector of length \code{p}. The posterior
  estimates of \eqn{\beta}.
}
\description{
This function runs \code{\link{succotash_em}} repetitively, keeping
the highest local mode. It then returns posterior summaries.
}
\details{
Let \eqn{Y} (\eqn{p} by \eqn{1}) be multivariate normal with mean
\eqn{\beta + \alpha Z} and diagonal covariance \eqn{\Sigma}, where
\eqn{\alpha} and \eqn{\Sigma} are both known. If \eqn{\beta} is
assumed to be a mixture of normals with known variances and unknown
mixing proportions \eqn{\pi} (\eqn{p} by \eqn{1}), then this
function will maximize the likelihood over \eqn{Z} and
\eqn{\pi}. It does this by running the EM algorithm implemented in
\code{\link{succotash_em}} many times at different starting points.

The defaults are to run the first EM algorithm using the
\code{"zero_conc"} option for \code{pi_init_type}, then use the
\code{"random"} option for every other EM run.
}
\seealso{
\code{\link{succotash_em}},
    \code{\link{succotash_summaries}}.
}

